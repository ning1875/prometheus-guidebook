

# 【模块6】k8s多集群管理平台和cmdb
- 第1章 前置准备工作
  - 1.1 准备工作
  - 1.2 官方的dashboard控制台安装
  - 1.3 解决登陆问题
  - 1.4 官方的dashboard控制台使用并总结特点
  - 1.5 k8s平台都要做哪些模块
  - 1.6 使用client-go操作集群

- 第2章 多集群操作之准备工作
  - 2.1 incluster连接集群源码解读
  - 2.2 设计连接集群的表
  - 2.3 多集群操作菜单
  - 2.4 k8s-icon
  - 2.5 mock-cluster数据
  - 2.6 构造k8s多集群的cache
  - 2.7 如何通过kconfig内容生产client
  - 2.8 测试list-node
  - 2.9 用快速搭建脚本搭建1.27新集群-1
  - 2.10 用快速搭建脚本搭建1.27新集群-2
  - 2.11 再搭建一个master

- 第3章 多集群管理权限限制
  - 3.1 准备多个集群的kubeconfigs
  - 3.2 遍历读取kc目录
  - 3.3 抽象公共超时ctx方法
  - 3.4 menu按模块进行分类的思路
  - 3.5 按角色分类menu
  - 3.6 测试效果
  - 3.7 解决id乱序问题
  - 3.8 按角色拆分api
  - 3.9 k8s集群管理限定集群管理员角色访问
  - 3.10 定义k8s集群管理role

- 第4章 多集群管理前端
  - 4.1 k8s管理平台存储方式2种流派
  - 4.2 解决子菜单问题
  - 4.3 k8s集群列表和接口
  - 4.4 运行环境特殊展示
  - 4.5 设计表单
  - 4.6 创建和更新接口
  - 4.7 设计探活方式
  - 4.8 给集群添加一些信息字段
  - 4.9 进行测试
  - 4.10 展示集群最近一次探活结果

- 第5章 集群节点操作准备
  - 5.1 展示集群探活失败原因
  - 5.2 查看之前的平台代码中node部分
  - 5.3 关于node都需要做什么功能
  - 5.4 获取指定集群节点原始列表的接口
  - 5.5 节点列表菜单和测试
  - 5.6 设计one-node结构体
  - 5.7 下载k8s源码
  - 5.8 构造节点封装公共kc方法
  - 5.9 解决临时文件删除错误的问题
  - 5.10 手动给version接口添加超时控制

- 第6章 模仿k8s源码获取节点基础信息
  - 6.1 测试version超时控制
  - 6.2 status状态取值
  - 6.3 mock-data的时候模拟创建node
  - 6.4 终于在k8s源码中找到了get-node源码
  - 6.5 仿照k8s源码进行node状态编写
  - 6.6 node-role的获取
  - 6.7 Age处理并测试
  - 6.8 获取节点上的pod方法
  - 6.9 标签和污点


- 第7章 获取节点上的资源信息
  - 7.1 allocatable和capacity
  - 7.2 request值如何获取
  - 7.3 计算百分比时request很大问题
  - 7.4 搜索k8s源码describe node中的资源计算
  - 7.5 再次计算百分比
  - 7.6 format的时候使用string替换value
  - 7.7 安装metrics-server
  - 7.8 使用metrics-client-set
  - 7.9 获取机器的使用率
  - 7.10 format使用率


- 第8章 前端展示节点列表
  - 8.1 前端集群下拉列表选择器
  - 8.2 后端获取集群列表的接口
  - 8.3 遇到问题table的beforeFetch获取数据为空
  - 8.4 切换下拉集群重载表格
  - 8.5 下拉列表进行美化失败
  - 8.6 下载dashboard源码学习分页
  - 8.7 手动分页后端代码
  - 8.8 测试并优化速度
  - 8.9 表格字段展示
  - 8.10 调度状态Switch展示和开关调度

- 第9章 集群节点操作之调度标签污点
  - 9.1 调度状态切换的公共方法
  - 9.2 测试单个按钮和批量操作
  - 9.3 按pod数量排序
  - 9.4 打标签操作的batch后端接口
  - 9.5 前端将labels进行预处理
  - 9.6 修复label-nil-map问题
  - 9.7 标签tooltip展示
  - 9.8 污点配置的yaml解析
  - 9.9 污点配置的后端接口
  - 9.10 如何在index中导入多个drawer

- 第10章 集群节点操作之驱逐
  - 10.1 污点drawer配置并测试校验
  - 10.2 污点配置缩进问题
  - 10.3 污点配置后端去重
  - 10.4 去掉污点的前后端操作
  - 10.5 展示污点
  - 10.6 驱逐节点的后端接口
  - 10.7 单个操作和batch操作
  - 10.8 收尾和TODO

- 第11章 集群节点详情展示
  - 11.1 详情的菜单和跳转
  - 11.2 考虑布局和detail接口
  - 11.3 通过query去查询节点详情
  - 11.4 详情拼接
  - 11.5 详情采用desc组件
  - 11.6 pod列表表格
  - 11.7 convertPod方法
  - 11.8 getPodsListByNodeName接口
  - 11.9 解决pod表格不显示问题
  - 11.10 调整样式和位置
  - 11.11 进行美化
  - 11.12 节点condition列表
  - 11.13 节点event转换方法
  - 11.14 节点event列表
  - 11.15 list加速和搜索
  - 11.16 总结

【模块6】k8s多集群管理 第12-16 集群管理员yaml和pod日志

- 第12章 集群管理员yaml操作
  - 12.1 总结集群管理员的操作
  - 12.2 调研helm-web
  - 12.3 helm 使用client-go操作
  - 12.4 设计yaml-apply的web化
  - 12.5 设计模板和task表
  - 12.6 模板和task的mock
  - 12.7 applyTask的变量替换
  - 12.8 DynamicClient的使用
  - 12.9 apply-yaml的后半段
  - 12.10 模板的3个api方法
  - 12.11 任务的3个api方法
  - 12.12 菜单和前端列表
  - 12.13 模板操作的前端
  - 12.14 任务操作的表单
  - 12.15 完成任务操作功能
  - 12.16 修复DynamicClient的bug
  - 12.17 进行测试
  - 12.18 taskYaml文件下载

- 第13章 集群管理员pod列表
  - 13.1 pod操作预期exec-logtail-websocket
  - 13.2 集群和命名空间联动的前端组件
  - 13.3 cache中获取集群的ns列表
  - 13.4 ns联动后端数据接口
  - 13.5 进行测试
  - 13.6 pod后端列表接口
  - 13.7 处理选择所有namespace的情况
  - 13.8 ns切换重新请求pod列表
  
- 第14章 集群管理员pod操作
  - 14.1 非tail型查看pod日志的样例
  - 14.2 route-link跳转传参
  - 14.3 获取pod容器列表的接口
  - 14.4 查看容器日志的后端方法
  - 14.5 选择容器后再查看日志
  - 14.6 支持选择日志行数
  - 14.7 总结容器日志和14个没声音视频的总结
  - 14.8 日志文件下载

- 第15章 基于websocket的工作
  - 15.1 调研vben的websocket
  - 15.2 gorilla-websocket使用-1
  - 15.3 gorilla-websocket使用-2
  - 15.4 编写ws对接logtail日志的demo
  - 15.5 ws测试
  - 15.6 小结
  - 15.7 对比之前写法

- 第16章 实现logtail效果
  - 16.1 先写前端日志跳转和select准备
  - 16.2 完成ws的准备
  - 16.3 调研实现日志滚动
  - 16.4 解决前端容器日志滚动
  - 16.5 清屏操作按钮
  - 16.6 研究日志换行
  - 16.7 模仿k8s源码中换行的处理
  - 16.8 podTailLog后端接口
  - 16.9 前端对接出现ws初始化问题
  - 16.10 固定容器访问tailLog
  - TODO 日志换行 ws地址 podLog后端接口


【模块6】k8s多集群管理 第17-21 webshell-dep-Configmap管理

- 第17章 pod的webshell
  - 17.1 进行调研webscoket-xterm 
  - 17.2 vue3使用xterm之安装
  - 17.3 摸索xterm的使用
  - 17.4 解决status-地址-ws初始化
  - 17.5 xterm和websocket整合
  - 17.6 学习k8s源码中exec的操作
  - 17.7 后端模拟一个exec服务端
  - 17.8 进行联调
  - 17.9 调整窗口大小和颜色
  - 17.10 实现后端接口
  - 17.11 进行测试
  - 17.12 解决sh-bash-dash选择的问题
  - 17.13 整理排序问题
  - 17.14 总结pod的webshell


- 第18章 pod-yaml和deployment列表
  - 18.1 完成后端接口先转json再转yaml
  - 18.2 对接前端
  - 18.3 补全apiVersion和kind
  - 18.4 去掉managedFields和yaml文件下载
  - 18.5 思考后面3个对象的操作
  - 18.6 deployment列表
  - 18.7 定义convert之后的对象
  - 18.8 执行转化动作
  - 18.9 完成接口
  - 18.10 动作之set-image更新某个容器镜像准备
  - 18.11 动作之set-image之前端准备

- 第19章 deployment动作
  - 19.1 动作之set-image-表单
  - 19.2 动作之set-image-后端接口
  - 19.3 测试多容器的set-image
  - 19.4 scale扩缩容的模态框
  - 19.5 scale扩缩容的表单
  - 19.6 scale扩缩容接口和联调
  - 19.7 单个删除
  - 19.8 跨namespace批量删除
  - 19.9 学习k8s源码中重启的逻辑
  - 19.10 完成rollout-restart后端的接口
  - 19.11 展示和下载yaml

- 第20章 configmap管理
  - 20.1 了解configmap的基础知识
  - 20.2 准备列表和转化方法
  - 20.3 编辑内容的li列表
  - 20.4 解决for遍历bind-value错误
  - 20.5 研究增删key的按钮
  - 20.6 单独一个展示内容的按钮
  - 20.7 模拟工单中的流程管理动态表格做
  - 20.8 完成动态表单
  - 20.9 后端更新cm的接口
  - 20.10 yaml文件展示和下载

- 第21章 svc管理
  - 21.1 研究antd原生的动态嵌套表单
  - 21.2 把嵌套表单改造成vue3的写法
  - 21.3 后端接口获取svc列表
  - 21.4 学习k8s源码中svclist方法
  - 21.5 前端对接表格
  - 21.6 把原生form嵌入drawer之宽度设置
  - 21.7 把原生form嵌入drawer之布局
  - 21.8 标签选择器组
  - 21.9 namespace配置
  - 21.10 编辑模式传参之ports
  - 21.11 模拟请求
  - 21.12 美化页面
  - 21.13 创建和更新何必到一个后端接口里面
  - 21.14 编辑时禁止name-ns-type变更
  - 21.15 端口name必填
  - 21.16 ns的下拉列表
  - 21.17 批量删除svc和cm
  - 21.18 展示和下载svc的yaml

【模块6】k8s多集群管理 第22-25 面向运维平台的项目应用实例设计
- 第22章 面向运维和研发k8s管理平台内容
  - 22.1 运维和研发在使用k8s时关心什么
  - 22.2 设计的核心对象-应用和实例的关系
  - 22.3 项目表设计
  - 22.4 应用表设计和mock数据
  - 22.5 实例表设计

- 第23章 app表字段设计
  - 23.1 目的是简化用户配置Deployment的过程
  - 23.2 dep的核心字段和非必填字段
  - 23.3 抽取容器核心字段的单独结构体
  - 23.4 容器卷配置
  - 23.5 容器和svc端口配置
  - 23.6 创建实例并操作Deployment的时机
  - 23.7 多集群分配问题
  - 23.8 mock-project-app
  - 23.9 最深范围创建instance的接口
  - 23.10 在实例中处理env继承自app的问题

- 第24章 instance创建过程中的Deployment和svc生成
  - 24.1 覆盖策略command-args
  - 24.2 resource处理
  - 24.3 多重处理集群级别默认的resource配置
  - 24.4 合并处理volume和mounts
  - 24.5 测试创建Deployment
  - 24.6 解决args和command问题
  - 24.7 volumeMounts依赖的数据fullfill
  - 24.8 解决kset缓存生成慢导致panic
  - 24.9 验证configmap挂载
  - 24.10 验证环境变量和标签

- 第25章 验证Deployment和svc生成
  - 25.1 验证resource资源的多级继承和优先覆盖
  - 25.2 通过断点排查pod端口不设置的问题
  - 25.3 拼接svc的元数据
  - 25.4 Deployment创建和更新合并在一起
  - 25.5 验证svc的创建结果
  - 25.6 权限限制复用服务树节点校验的逻辑
  - 25.7 验证instance更新带动Deployment更新
  - 25.8 1个app下面多个实例共存为多分支用提供能力
  - 25.9 给svc和dep添加标签选择指向app维度

【模块6】k8s多集群管理 第26-29 实例重启和Deployment调优配置
- 第26章 实例重启和删除-app维度操作
  - 26.1 删除instance级联删除Deployment逻辑
  - 26.2 批量重启动作
  - 26.3 查询app下属的实例列表返回dep的状态
  - 26.4 app创建和更新的基础操作
  - 26.5 app更新时需要级联更新Deployment和svc
  - 26.6 进行测试发现labels更新有问题
  - 26.7 解决dep的标签选择器不可变更的问题
  - 26.8 测试svc更新和删除app级联svc

- 第27章 Deployment调优配置(这里的内容是统一配置，不放开给用户的)
  - 27.1 pod的探针设置
  - 27.2 进行测试并解决cmd和args首元素为空的问题
  - 27.3 反亲和(多副本打散在多节点)代码
  - 27.4 解决没打散的问题
  - 27.5 内部私有镜像仓库问题

- 第28章 前端之项目project操作
  - 28.1 准备菜单
  - 28.2 准备列表
  - 28.3 绑定服务树层级过滤
  - 28.4 权限校验不在拉取服务树节点时而在创建或更新时校验
  - 28.5 验证非super角色的权限问题          
  - 28.6 修复服务树子节点不显示运维负责人列表的问题          
  - 28.7 删除接口          
  - 28.8 从项目名称跳转至应用列表的准备         


- 第29章 前端之应用application操作
  - 29.1 准备菜单和列表-1
  - 29.2 准备菜单和列表-2
  - 29.3 准备2个项目和4个应用
  - 29.4 支持跳转根据项目id查询所属的应用列表
  - 29.5 新增和编辑表单的基础字段
  - 29.6 准备复杂的表单
  - 29.7 从属项目和绑定服务树的下拉列表
  - 29.8 填充好非嵌套字段
  - 29.9 嵌套字段envs
  - 29.10 解决commands字符串数组的问题

【模块6】k8s多集群管理 第30-32 最复杂的表单之应用application表单
- 第30章 应用application表单
  - 30.1 同理的args和端口设置
  - 30.2 复杂的volume挂载配置
  - 30.3 编辑直接使用这个表单
  - 30.4 解决前端数组类型编辑的问题-后转前
  - 30.5 解决后端数组类型编辑的问题-前转后
  - 30.6 表单请求的问题
  - 30.7 validate校验
  - 30.8 解决这个问题
  - 30.9 创建的接口
  - 30.10 更新的接口
  - 30.11 解决dep的探针和svc为空的情况
  - 30.12 从创建应用到pod的完整测试
  - 30.13 排查app更新的标签错误问题
  - 30.14 生成Deployment只走instance不要在app再维护一份
  - 30.15 进行测试发现标签更新的问题
  - 30.16 解决方法是将选择的标签固定即可
  - 30.17 创建后跳转编辑按钮
  - 30.18 字段多的时候一键复制已有表单
  - 30.19 app删除

- 第31章 实例instance的表单和操作
  - 31.1 菜单和列表
  - 31.2 几个和Deployment关联特殊字段
  - 31.3 指定appId查询
  - 31.4 instance创建和更新的表单
  - 31.5 和app一样的stringArray字段处理
  - 31.6 新增和更新的接口
  - 31.7 解决更新错误的问题
  - 31.8 把Deployment和svc的生成拆开一下之svc的创建
  - 31.9 把Deployment和svc的生成拆开一下之dep创建

- 第32章 实例instance的删除-重启-和pod日志
  - 32.1 批量删除操作
  - 32.2 批量重启操作
  - 32.3 规范一下后端生成yaml文件的目录
  - 32.4 规范一下日志的目录
  - 32.5 能否复用我们之前写好的容器日志
  - 32.6 准备根据Deployment获取pod的表格
  - 32.7 复用之前exec和log页面
  - 32.8 非k8s管理员的exec和log菜单是否可见的问题
  - 32.9 api权限的问题
  - 32.10 处理casbin=All的鉴权问题

【模块6】k8s多集群管理 第33-34 cronjob和收尾
- 第33章 cronjob
  - 33.1 修复创建instance的问题
  - 33.2 确定instance重名的范围和它的反亲和性配置
  - 33.3 思考cronjob的配置项
  - 33.4 设置表结构
  - 33.5 过滤状态字段和表单字段
  - 33.6 生成cronjob的方法
  - 33.7 新增和更新的接口
  - 33.8 进行测试
  - 33.9 cronjob字段优化添加标签
  - 33.10  批量删除
  - 33.11 获取cj最近调度的pod
  - 33.12 查看最近调度pod的日志
  - 33.13 解决复制cj创建后报错的问题
  - 33.14 项目跳转cronjob查询
  - 33.15 给job添加污点和容忍

- 第34章 总结k8s模块
  - 34.1 总结需求 回归功能



## 33.15 给job添加污点的问题
- k8s集群 公有云 分节点池
- 隔离措施：在线和离线分开：cronjob 偏离线任务，Deployment偏在线任务
- 最简单的模式：Deployment和 cronjob部署到不同的节点池里面：2批机器
```yaml
- key: "nodegroup"
  operator: "Equal"
  value: "job"
  effect: "NoSchedule"
```

## 创建cj的错误
```shell
创建cj调用apply cj 创建或更新错误:创建cronjob错误:CronJob.batch \"cronjob-project-mock-0-prom\" is invalid:
 
 spec.jobTemplate.spec.selector: Invalid value: 
 v1.LabelSelector{MatchLabels:map[string]string{\"infra_cronjob_name\":\"prom\", \"infra_project_name\":\"project-mock-0\"
 , \"infra_stree_node\":\"tencent.IEG.Game.CF\"}, MatchExpressions:[]v1.LabelSelectorRequirement(nil)}: `
 selector` will be auto-generated CronJob.batch \"cronjob-project-mock-0-prom\" is invalid: spec.jobTemplate.spec.selector:
  Invalid value: v1.LabelSelector{MatchLabels:map[string]string{\"infra_cronjob_name\":\"prom\", 
  \"infra_project_name\":\"project-mock-0\", \"infra_stree_node\":\"tencent.IEG.Game.CF\"}, 
  MatchExpressions:[]v1.LabelSelectorRequirement(nil)}: `selector` will be auto-generated",
    "type": ""
}
```


- 第33章 Configmap的操作是否要做?


# 更新app报错
```shell
    "message": "更新app遍历instance创建Deployment或更新错误:更新deployment对象错误:Deployment.apps \"update-app-rc01\" 
    is invalid: spec.selector: Invalid value: 
    v1.LabelSelector{MatchLabels:map[string]string{\"infra_app_name\":\"update-app\", \"infra_instance_name\":\"rc01\", \"infra_stree_node\":\"tencent.IEG.Game.CF\", \"k223\":\"v3\", \"new\":\"new\", \"run\":\"rc\"}, 
    MatchExpressions:[]v1.LabelSelectorRequirement(nil)}: 
    field is immutable Deployment.apps \"update-app-rc01\" is invalid: spec.selector: Invalid value: v1.LabelSelector{MatchLabels:map[string]string{\"infra_app_name\":\"update-app\", \"infra_instance_name\":\"rc01\", \"infra_stree_node\":\"tencent.IEG.Game.CF\", \"k223\":\"v3\", \"new\":\"new\", \"run\":\"rc\"}, 
    MatchExpressions:[]v1.LabelSelectorRequirement(nil)}: field is immutable",

```




pod反亲和：
pod镜像拉取secret：内部私有镜像仓库：配置 secret 
pod探针：通用的tcp



# 23.6 创建实例并操作Deployment的时机： 什么时候会触发操作Deployment 
- 创建实例：创建 Deployment 和 svc
- 修改实例的配置：更新 Deployment 和 svc
- 创建应用：不会操作：
- 更新应用：如果有实例：遍历所有实例更新，如果没有则不管
- 实例比应用多的字段
  - 副本数
  - 镜像地址



## pod按节点打散
```yaml
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: infra_instance_name
                  operator: In
                  values:
                  - nginx06
              namespaceSelector: {}
              topologyKey: kubernetes.io/hostname
            weight: 100

```
## master可调度
```yaml
root@k8s-master01:~# kubectl taint node k8s-master01 node-role.kubernetes.io/control-plane-
node/k8s-master01 untainted
root@k8s-master01:~# kubectl get pod -o wide |grep 08
k8s-app-nginx-nginx08-59598cb646-q2qhx   1/1     Running             0                3m29s   10.100.66.7     k8s-ingress01   <none>           <none>
k8s-app-nginx-nginx08-59598cb646-qlqv7   0/1     ContainerCreating   0                69s     <none>          k8s-master01    <none>           <none>
root@k8s-master01:~# kubectl get pod -o wide |grep 08
k8s-app-nginx-nginx08-59598cb646-q2qhx   1/1     Running             0                3m30s   10.100.66.7     k8s-ingress01   <none>           <none>
k8s-app-nginx-nginx08-59598cb646-qlqv7   0/1     ContainerCreating   0                70s     <none>          k8s-master01    <none>           <none>
root@k8s-master01:~# 

```

# 23.1 Deployment核心字段
```yaml
      containers:
      - args:
        - --cert-dir=/tmp
        - --secure-port=4443
        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
        - --kubelet-use-node-status-port
        - --metric-resolution=15s
        - --kubelet-insecure-tls
        image: registry.cn-beijing.aliyuncs.com/ning1875_haiwai_image/metrics-server:v0.6.4
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /livez
            port: https
            scheme: HTTPS
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
        name: metrics-server
        ports:
        - containerPort: 4443
          name: https
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /readyz
            port: https
            scheme: HTTPS
          initialDelaySeconds: 20
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
        resources:
          requests:
            cpu: 100m
            memory: 200Mi
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 1000
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /tmp
          name: tmp-dir
      dnsPolicy: ClusterFirst
      nodeSelector:
        kubernetes.io/os: linux
      priorityClassName: system-cluster-critical
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      serviceAccount: metrics-server
      serviceAccountName: metrics-server
      terminationGracePeriodSeconds: 30
      volumes:
      - emptyDir: {}
        name: tmp-dir

```
- 容器的个数：
  - 先固定1个：多容器的场景是比较少的
  - 先不支持init容器
- 容器字段
  - 镜像是不填的：模板中不能填具体的配置
> 23.2 dep的核心字段和非必填字段
- 环境变量 


# 22章开始：运维和研发在使用k8s时关心什么
> 核心关注的k8s对象和操作
- 工作负载： Deployment
  - 为什么不讨论ds :ds 直接和node交互一般都是集群管理员做的
  - 当然不可以直接拿Deployment spec字段过来： gorm不支持 ，
  - 主要目的是简化用户配置Deployment 的过程。所以肯定不会让它全部填yaml写入
  - sts 比较复杂，少量人用
  - 关注Deployment的配置：持久化：存储到mysql
  - 动作：重启
  - 部署：换镜像
- 配置：Configmap 和secret(较少)
  - 动作 增删改查
- svc：暴露服务：grpc http给其他服务调用
- job和cronjob：配置任务
- pod：看日志 、exec执行命令
- 域名：ingress来做？？

> 权限
- 对比我们之前写完的集群管理员：对接底座的 角色-- k8s集群管理员
  - 角色关联 菜单：菜单决定前端是否可见
  - 角色关联 api：api决定后端接口是否有权限
- 这里的权限：结合服务树做
  - 可以结合ns 
  - 服务树有权限限制： 你这个组关联的微服务：Deployment 都和服务树节点进行绑定
  - 有某服务树节点的权限 就可以 查看 操作上述的对象

> 核心对象
- 分组概念： 项目表
  - 张三是电商组的运维，维护100个Deployment
  - 上述dep怎么归类：项目--> 服务树有明确层级含义的
  - g.p.a :需要限定一下 服务树层级含义
  - 第一级： 公司
  - 第二级：大部门
  - 第三级：项目 ：归结到第三层级
  - 第四级：具体的应用了
- 如何体现 每一个应用呢： 应用表 和实例表
  - 是否=Deployment ：答案是否：混合其他对象
  - 应用和Deployment什么关系：1对多，实例是应用的实例化产物：Deployment-yaml生成
    - mysql是一个app 
    - mysql-57 就是这个app的一个实例
    - mysql-58 就是这个app的一个实例 代表镜像更新了
    - mysql-57-config 就是这个app的一个实例 代表镜像没变，我的配置变了：程序启动参数
    - 多分支泳道：共同运行
  
- 后面对接发布系统：gitlab-ci 新建分支直接调用k8s模块 新增一个实例  


# 集群管理员模块 要不要实现下面3个对象
- deployment 管理
  - scale 扩缩容
  - 删除
  - rollout restart
    - kubectl 只是给Deployment 的yaml中设置一个patch 内容：restartAt时间 kubectl.kubernetes.io/restartedAt ：cm 会去处理 
    - 它为什么只加了一个annotation ，重启，并不想改变 pod的spec配置，所以就简单的加一个 不痛不痒的配置就能触发
    - 调谐 判断 有一点点 变化 就触发
  - set image 更新某个容器镜像
- svc 管理
  - 编辑 labelSelector 修改选择器
  - 修改类型
- configmap 管理
  - 查看内容
  - 修改内部 某个文件的内容
  - 增加文件和内容



# webshell 调研
- https://gitee.com/moujun/mserver-terminal
- 颜色
- 调整窗口大小
- 命令行 提示  root@nginx-bigdevops-8649cc8bb7-4b4v7:/# vs #  sh vs shell
- ctrl L 清屏 ok
- 参考 https://www.cnblogs.com/duyixu/p/17346370.html

## kubectl exec 执行过程
- 源码地址 D:\nyy_work\go_path\src\github.com\kubernetes\kubernetes\staging\src\k8s.io\kubectl\pkg\cmd\exec\exec.go
- 首先创建一个 pod的subresource exec
- 拼接 PodExecOptions
-  remotecommand.NewSPDYExecutor 创建exec对象
- 再执行 stream 方法
- 怎么样把数据 进行交互呢：handler 

## 几种数据
- heartbeat心跳
- resize 窗口
- 发送数据


## xterm
```shell
# 安装

pnpm install xterm  @xterm/addon-attach @xterm/addon-fit  lodash  -ignore-workspace-root-check

```
# ws日志地址 
ws://localhost:80/noAuth/getPodContainerTailLog?cluster=bigdevops&namespace=kube-system&podName=prometheus-0&container=prometheus

# k8s client-go 读取日志换行
- D:\nyy_work\go_path\src\github.com\kubernetes\kubernetes\staging\src\k8s.io\kubectl\pkg\cmd\logs\logs.go


# websocket
- 后端 https://github.com/gorilla/websocket/tree/main/examples/chat
- messageType:=1 代表ping消息：心跳 2023/12/10 10:28:37 ws.ReadMessage.print messageType:1 msg:ping
- messageType https://github.com/gorilla/websocket/blob/main/conn.go#L66
> 后端需要处理心跳 否则的话ws就会断开
- 


# helm 

- helm 操作可以参考这个 https://github.com/mittwald/go-helm-client


- effect: NoSchedule
  key: node-role.kubernetes.io/control-plane
- effect: NoSchedule
  key: node.kubernetes.io/unschedulable

# 安装metrics-server
```shell
kubectl -n kube-system set image dep+loyment/metrics-server metrics-server=registry.cn-beijing.aliyuncs.com/ning1875_haiwai_image/metrics-server:v0.6.4

- 修改后的容器段如下
```yaml-0..
0- --kubelet-insecure-tls # 加上该启动参数
        image: ccr.ccs.tencentyun.com/mirrors/metrics-server:v0.5.0 # 国内集群，请替换成这个镜像
```
```


# 模仿 describe-node 计算资源总量
- 效果
```shell
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                950m (23%)  100m (2%)
  memory             240Mi (3%)  340Mi (4%)
  ephemeral-storage  0 (0%)      0 (0%)

```
- 代码在 D:\nyy_work\go_path\src\github.com\kubernetes\kubernetes\staging\src\k8s.io\kubectl\pkg\describe\describe.go

# 6.4 终于在k8s源码中找到了get-node源码
- D:\nyy_work\go_path\src\github.com\kubernetes\kubernetes\pkg\printers\internalversion\printers.go
```shell
root@k8s-master01:~# kubectl get node 
NAME                    STATUS     ROLES           AGE     VERSION
bigdevops-mock-node-0   NotReady   <none>          3m38s   
bigdevops-mock-node-1   NotReady   <none>          3m38s   
bigdevops-mock-node-2   NotReady   <none>          3m38s   
bigdevops-mock-node-3   NotReady   <none>          3m38s   
bigdevops-mock-node-4   NotReady   <none>          3m38s   
k8s-ingress01           Ready      <none>          110d    v1.27.0
k8s-master01            Ready      control-plane   110d    v1.27.0



	row.Cells = append(row.Cells, obj.Name, strings.Join(status, ","), roles, translateTimestampSince(obj.CreationTimestamp), obj.Status.NodeInfo.KubeletVersion)
	if options.Wide {
		osImage, kernelVersion, crVersion := obj.Status.NodeInfo.OSImage, obj.Status.NodeInfo.KernelVersion, obj.Status.NodeInfo.ContainerRuntimeVersion
		if osImage == "" {
			osImage = "<unknown>"
		}
		if kernelVersion == "" {
			kernelVersion = "<unknown>"
		}
		if crVersion == "" {
			crVersion = "<unknown>"
		}
		row.Cells = append(row.Cells, getNodeInternalIP(obj), getNodeExternalIP(obj), osImage, kernelVersion, crVersion)
	}

```


# 使用k8s运维平台的人 角色 其实分成2波人
> 01 k8s集群管理员：保障集群稳定性
-
> 02 应用运维：更关注他自身维护的pod或者deployment工作负载


| 角色    | 关注点 | 权限                    | 是否关注节点 | 日常操作                                   |
|-------|-----|-----------------------|--------|----------------------------------------|
| 集群管理员 |   保障集群稳定性  | 最高权限                  | 核心     | 集群扩缩容<br> 升级 <br> 必备组件维护               |
| 应用运维  | 更关注他自身维护的pod或者deployment工作负载    | 只需要给特定ns的deployment权限 | 不关注节点  | 部署业务服务<br> 查看失败日志 <br> 配置ingress暴露服务域名 |



# 背景 k8s单一集群的所有资源 都是存储在它的etcd中

## 流派01: web管理平台不用mysql 等rds存储数据 ，通过client-go读写etcd
- 比如 kube-dashboard ：包括我之前写的第一版 k8s管理平台

## 流派02: web管理平台 使用mysql 等rds存储数据
- 不认etcd中的数据
- 只认mysql
- 操作都需要通过web 到mysql --> 调用apiserver 操作etcd
- 举例：在页面上创建一个deployment
  - 相比写全量yaml
  - 做局部配置
  - 生成yaml apply
- 如果跳过 web 直接去集群里操作：web是看不到的
- 上层的应用：pod 控制器调谐：


# 规划 ：混用
- 集群操作 大部分 是直接etcd
- 普通运维：deployment 操作 要用rds


# 权限
> 对于集群管理来说 ：绑定role ，role中去关联菜单和api

> 对于普通用户 ：跟服务树对接


# 关于5.3 关于node都需要做什么功能
> 查看类
- 查看node基础信息
```shell
NAME            STATUS   ROLES           AGE    VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME
k8s-ingress01   Ready    <none>          104d   v1.27.0   192.168.0.82   <none>        Ubuntu 22.04.2 LTS   5.15.0-88-generic   containerd://1.6.21
k8s-master01    Ready    control-plane   104d   v1.27.0   192.168.0.81   <none>        Ubuntu 22.04.2 LTS   5.15.0-88-generic   containerd://1.6.21

```
- 资源情况
  - cpu mem disk pod 申请值 可用值 总值
  - 使用率 关乎 metrics-server的接口
- event状态
- pod-on-node 类似 describe node时看到的
> 操作类
- cordon /uncordon 节点
- taint 打污点
- drain 驱逐
- labels 打标签